{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpaca Data Validation and Loading (Colab Demo)\n",
    "\n",
    "This notebook demonstrates how to validate, load, and inspect Alpaca-format data for LLM training and evaluation.\n",
    "\n",
    "- Validates all datasets in `data/processed/` using your project's schema\n",
    "- Loads data with batching using `TemplateDataLoader`\n",
    "- Runs a dry-run evaluation with a dummy evaluator\n",
    "\n",
    "**Instructions:**\n",
    "- Upload your code and data, or clone your repo in Colab.\n",
    "- Adjust paths as needed if your directory structure differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /opt/homebrew/bin/pip: bad interpreter: /opt/homebrew/opt/python@3.11/bin/python3.11: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 1. Install dependencies (if needed)\n",
    "!pip install torch transformers datasets wandb matplotlib seaborn pandas ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Optional) Clone your repo or upload files\n",
    "If your repo is private, use a personal access token or upload manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Set up Python path for src/ imports\n",
    "import sys, os\n",
    "os.chdir(\"..\")  # Move up from /notebooks/ to project root\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 4. Validate Alpaca-format data\n",
    "# Checks all JSON files in `data/processed/` for schema compliance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidate_alpaca_schema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlpacaSchemaValidator\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/processed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.data.validate_alpaca_schema import AlpacaSchemaValidator\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data/processed')\n",
    "english_tokens_path = data_dir / 'english_tokens.json'\n",
    "validator = AlpacaSchemaValidator(english_tokens_path if english_tokens_path.exists() else None)\n",
    "reports = validator.validate_dir(data_dir)\n",
    "for report in reports:\n",
    "    print(f'\\nFile: {report[\"file\"]}')\n",
    "    if 'total' in report:\n",
    "        print(f'  Total examples: {report[\"total\"]}')\n",
    "        print(f'  Valid: {report[\"valid\"]}')\n",
    "        print(f'  Invalid: {report[\"invalid\"]}')\n",
    "        if report['invalid'] > 0:\n",
    "            for err in report['errors']:\n",
    "                print(f'    Example #{err[\"index\"]}: {err[\"errors\"]}')\n",
    "    else:\n",
    "        print(f'  Error: {report.get(\"error\", \"Unknown error\")}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"## 5. Load and inspect data using TemplateDataLoader\\n\",\n",
    "    \"Loads Alpaca-format data and prints stats and a sample batch.\\n\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import TemplateDataLoader, BatchConfig\n",
    "\n",
    "loader = TemplateDataLoader(\n",
    "    data_dir=data_dir,\n",
    "    batch_config=BatchConfig(batch_size=4, max_length=128, shuffle=False)\n",
    ")\n",
    "stats = loader.get_stats()\n",
    "print('Stats:', stats)\n",
    "for batch in loader.train_batches():\n",
    "    print('Batch:', batch)\n",
    "    break  # Show only the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"## 7. (Optional) Continue with your actual training/evaluation code here\\n\",\n",
    "    \"You can expand this notebook to load a real model, run fine-tuning, or perform real evaluation as needed.\\n\"\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
