{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525623e8",
   "metadata": {},
   "source": [
    "# Cloud GPU Environment Setup Guide\n",
    "\n",
    "This notebook provides step-by-step instructions for setting up GPU-accelerated environments for the LLM Spelling Project using:\n",
    "1. Google Colab\n",
    "2. Lightning.ai\n",
    "\n",
    "## Prerequisites\n",
    "- A Google account (for Colab)\n",
    "- A Lightning.ai account\n",
    "- Weights & Biases account\n",
    "- Hugging Face account\n",
    "\n",
    "## Environment Setup Overview\n",
    "1. Install required packages\n",
    "2. Configure authentication\n",
    "3. Set up data synchronization\n",
    "4. Test GPU availability\n",
    "5. Run example fine-tuning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d85212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth torch transformers datasets wandb dspy lightning matplotlib seaborn pandas jupyter notebook ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e31b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights & Biases setup\n",
    "import wandb\n",
    "wandb.login()  # You'll need to enter your API key\n",
    "\n",
    "# Hugging Face setup\n",
    "from huggingface_hub import login\n",
    "login()  # You'll need to enter your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yourusername/raspberry.git\n",
    "!cd raspberry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Initialize model with Unsloth optimizations\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # Example model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=512,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Example training configuration\n",
    "training_config = {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "}\n",
    "\n",
    "# The actual training code will depend on your specific dataset and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e5d39",
   "metadata": {},
   "source": [
    "## 2. Lightning.ai Setup\n",
    "\n",
    "### 2.1 Initial Setup\n",
    "1. Go to [Lightning.ai](https://lightning.ai/lars/home)\n",
    "2. Create a new project or open existing\n",
    "3. Select a GPU-enabled compute instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ee5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lightning.app\n",
    "name: llm-spelling-project\n",
    "compute:\n",
    "  type: gpu\n",
    "  size: medium  # Adjust based on needs\n",
    "requirements:\n",
    "  - unsloth\n",
    "  - transformers\n",
    "  - wandb\n",
    "  - dspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc42e22",
   "metadata": {},
   "source": [
    "## 3. Syncing Results and Models\n",
    "\n",
    "### 3.1 Using Weights & Biases\n",
    "W&B is the primary method for tracking experiments and syncing models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f220dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize a new run\n",
    "wandb.init(\n",
    "    project=\"llm-spelling\",\n",
    "    name=\"fine-tuning-run-1\",\n",
    "    config=training_config\n",
    ")\n",
    "\n",
    "# Log metrics during training\n",
    "wandb.log({\"loss\": 0.5, \"accuracy\": 0.95})\n",
    "\n",
    "# Save model artifacts\n",
    "wandb.save(\"./model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ddd3d",
   "metadata": {},
   "source": [
    "### 3.2 Using Hugging Face Hub\n",
    "For sharing models and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b63a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import push_to_hub\n",
    "\n",
    "# Save model to Hugging Face Hub\n",
    "model.push_to_hub(\"your-username/model-name\")\n",
    "tokenizer.push_to_hub(\"your-username/model-name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300f58e",
   "metadata": {},
   "source": [
    "## 4. Troubleshooting Tips\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "1. **GPU Out of Memory**\n",
    "   - Reduce batch size\n",
    "   - Enable gradient checkpointing\n",
    "   - Use 4-bit or 8-bit quantization\n",
    "   ```python\n",
    "   model.enable_gradient_checkpointing()\n",
    "   ```\n",
    "\n",
    "2. **Colab Runtime Disconnection**\n",
    "   - Save checkpoints frequently\n",
    "   - Use W&B for experiment tracking\n",
    "   - Keep browser tab active\n",
    "\n",
    "3. **Package Conflicts**\n",
    "   - Create a fresh environment\n",
    "   - Install packages in the correct order\n",
    "   - Check compatibility matrix\n",
    "\n",
    "4. **Authentication Issues**\n",
    "   - Verify API keys in environment variables\n",
    "   - Check token permissions\n",
    "   - Ensure proper login sequence\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Regular Checkpointing**\n",
    "   - Save model state every N steps\n",
    "   - Use W&B for experiment tracking\n",
    "   - Keep local copies of important data\n",
    "\n",
    "2. **Resource Management**\n",
    "   - Monitor GPU memory usage\n",
    "   - Use appropriate batch sizes\n",
    "   - Clean up unused variables\n",
    "\n",
    "3. **Version Control**\n",
    "   - Commit code changes regularly\n",
    "   - Use meaningful commit messages\n",
    "   - Tag important versions"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
